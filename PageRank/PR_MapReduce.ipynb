{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import itertools\n",
    "\n",
    "class MapReduce:\n",
    "    __doc__ = '''提供map_reduce功能'''\n",
    "\n",
    "    @staticmethod\n",
    "    def map_reduce(i, mapper, reducer):\n",
    "        '''\n",
    "        map_reduce:\n",
    "        param:\n",
    "        i:       MapReduce的输入集合\n",
    "        mapper:  自定义的mapper方法\n",
    "        reducer: 自定义的reducer方法\n",
    "        \n",
    "        return:  自定义reducer方法的返回列表\n",
    "        '''\n",
    "        intermediate = []  # 存放所有的(intermediate_key, intermediate_value)\n",
    "        # mapper映射阶段\n",
    "        for (key, value) in i.items():\n",
    "            intermediate.extend(mapper(key, value))\n",
    "\n",
    "        # sorted返回一个排序好的list，因为list中的元素是一个个的tuple，key设定按照tuple中第几个元素排序\n",
    "        # groupby把迭代器中相邻的重复元素挑出来放在一起,key设定按照tuple中第几个元素为关键字来挑选重复元素\n",
    "        # 下面的循环中groupby返回的key是intermediate_key，而group是个list，是1个或多个有着相同intermediate_key的(intermediate_key, intermediate_value)\n",
    "        groups = {}\n",
    "        for key, group in itertools.groupby(sorted(intermediate, key = lambda im: im[0]), key = lambda x: x[0]):\n",
    "            groups[key] = [y for x, y in group]\n",
    "        # groups是一个字典，其key为上面说到的intermediate_key，value为所有对应intermediate_key的intermediate_value\n",
    "        # 组成的一个列表\n",
    "        return [reducer(intermediate_key, groups[intermediate_key]) for intermediate_key in groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygraph.classes.digraph import digraph\n",
    "\n",
    "class PRMapReduce:\n",
    "    __doc__ = '''计算网页PageRank值'''\n",
    "\n",
    "    def __init__(self, dg):\n",
    "        self.damping_factor = 0.85    # 阻尼系数,即α\n",
    "        self.max_iterations = 100     # 最大迭代次数\n",
    "        self.min_delta = 10e-8        # 确定迭代是否结束的参数,即ϵ\n",
    "        self.num_of_pages = len(dg.nodes())    # 总网页数\n",
    "\n",
    "        # graph表示整个网络图。是字典类型\n",
    "        # graph[i][0] 存放第i网页的PR值\n",
    "        # graph[i][1] 存放第i网页的出链数量\n",
    "        # graph[i][2] 存放第i网页的出链网页列表\n",
    "        self.graph = {}\n",
    "        # 初始化self.graph字典\n",
    "        for node in dg.nodes():\n",
    "            self.graph[node] = [1.0 / self.num_of_pages, len(dg.neighbors(node)), dg.neighbors(node)]\n",
    "\n",
    "    def ip_mapper(self, input_key, input_value):\n",
    "        \"\"\"\n",
    "        param：\n",
    "        input_key:   网页名node\n",
    "        input_value: self.graph[input_key]\n",
    "        \n",
    "        return:\n",
    "        若无出链，即悬挂网页，则返回[(1，该网页的PR值)]；否则就返回[]\n",
    "        \"\"\"\n",
    "        if input_value[1] == 0:\n",
    "            return [(1, input_value[0])]\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    def ip_reducer(self, input_key, input_value_list):\n",
    "        \"\"\"\n",
    "        计算所有悬挂网页的PR值之和\n",
    "        param：\n",
    "        input_key:        根据ip_mapper的返回值来看，这个input_key为1\n",
    "        input_value_list: 所有悬挂网页的PR值\n",
    "        \n",
    "        return:\n",
    "        所有悬挂网页的PR值之和\n",
    "        \"\"\"\n",
    "        return sum(input_value_list)\n",
    "\n",
    "    def pr_mapper(self, input_key, input_value):\n",
    "        \"\"\"\n",
    "        mapper：\n",
    "        param：\n",
    "        input_key:   网页名node\n",
    "        input_value: self.graph[input_key]，即这个网页的相关信息\n",
    "        \n",
    "        return:\n",
    "        [(网页名, 0.0), (出链网页1, 出链网页1分得的PR值), (出链网页2, 出链网页2分得的PR值)...]\n",
    "        \"\"\"\n",
    "        return [(input_key, 0.0)] + [(out_link, input_value[0] / input_value[1]) for out_link in input_value[2]]\n",
    "\n",
    "    def pr_reducer_inter(self, intermediate_key, intermediate_value_list, dp):\n",
    "        \"\"\"\n",
    "        reducer：\n",
    "        param：\n",
    "        intermediate_key:        网页名node\n",
    "        intermediate_value_list: A所有分得的PR值的列表:[0.0,分得的PR值,分得的PR值...]\n",
    "        dp:                      所有悬挂网页的PR值之和\n",
    "        \n",
    "        return:\n",
    "        (网页名，计算所得的PR值)\n",
    "        \"\"\"\n",
    "        return (intermediate_key,\n",
    "                self.damping_factor * sum(intermediate_value_list) +\n",
    "                self.damping_factor * dp / self.num_of_pages +\n",
    "                (1.0 - self.damping_factor) / self.num_of_pages)\n",
    "\n",
    "    def page_rank(self):\n",
    "        \"\"\"\n",
    "        计算PR值，每次迭代都需要两次调用MapReduce；\n",
    "        一次是计算悬挂网页PR值之和，一次是计算所有网页的PR值\n",
    "        \n",
    "        return:\n",
    "        self.graph，其中的PR值已经计算好\n",
    "        \"\"\"\n",
    "        iteration = 1  # 迭代次数\n",
    "        change = 1  # 记录每轮迭代后的PR值变化情况，初始值为1保证至少有一次迭代\n",
    "        while change > self.min_delta:\n",
    "            print(\"Iteration: \" + str(iteration))\n",
    "\n",
    "            # 因为可能存在悬挂网页，所以才有下面这个dangling_list\n",
    "            # dangling_list存放的是[所有悬挂网页的PR值之和]\n",
    "            # dp表示所有悬挂网页的PR值之和\n",
    "            dangling_list = MapReduce.map_reduce(self.graph, self.ip_mapper, self.ip_reducer)\n",
    "            if dangling_list:\n",
    "                dp = dangling_list[0]\n",
    "            else:\n",
    "                dp = 0\n",
    "\n",
    "            # 因为MapReduce.map_reduce中要求的reducer只能有两个参数，而我们需要传3个参数（多了一个所有悬挂网页的PR值之和,即dp）\n",
    "            # 所以采用下面的lambda表达式来达到目的\n",
    "            # new_pr为一个列表，元素为:(网页名，计算所得的PR值)\n",
    "            new_pr = MapReduce.map_reduce(self.graph, self.pr_mapper, lambda x, y: self.pr_reducer_inter(x, y, dp))\n",
    "\n",
    "            # 计算此轮PR值的变化情况\n",
    "            change = sum([abs(new_pr[i][1] - self.graph[new_pr[i][0]][0]) for i in range(self.num_of_pages)])\n",
    "            print(\"Change: \" + str(change))\n",
    "\n",
    "            # 更新PR值\n",
    "            for i in range(self.num_of_pages):\n",
    "                self.graph[new_pr[i][0]][0] = new_pr[i][1]\n",
    "            iteration += 1\n",
    "        return self.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Change: 0.51\n",
      "Iteration: 2\n",
      "Change: 0.4335\n",
      "Iteration: 3\n",
      "Change: 0.36847499999999994\n",
      "Iteration: 4\n",
      "Change: 0.261003125\n",
      "Iteration: 5\n",
      "Change: 0.22185265624999995\n",
      "Iteration: 6\n",
      "Change: 0.18019365746527777\n",
      "Iteration: 7\n",
      "Change: 0.12644985148871524\n",
      "Iteration: 8\n",
      "Change: 0.10748237376540798\n",
      "Iteration: 9\n",
      "Change: 0.08406837309538487\n",
      "Iteration: 10\n",
      "Change: 0.06112828727369363\n",
      "Iteration: 11\n",
      "Change: 0.04973813076330205\n",
      "Iteration: 12\n",
      "Change: 0.03740431391358598\n",
      "Iteration: 13\n",
      "Change: 0.02915663342778904\n",
      "Iteration: 14\n",
      "Change: 0.02193371187673035\n",
      "Iteration: 15\n",
      "Change: 0.015767796030159015\n",
      "Iteration: 16\n",
      "Change: 0.013279129448596466\n",
      "Iteration: 17\n",
      "Change: 0.011129801130582678\n",
      "Iteration: 18\n",
      "Change: 0.007891044693363547\n",
      "Iteration: 19\n",
      "Change: 0.006707387989358937\n",
      "Iteration: 20\n",
      "Change: 0.005498354948285877\n",
      "Iteration: 21\n",
      "Change: 0.0038659204023243354\n",
      "Iteration: 22\n",
      "Change: 0.00328603234197572\n",
      "Iteration: 23\n",
      "Change: 0.0025934467028597974\n",
      "Iteration: 24\n",
      "Change: 0.0018553788938006077\n",
      "Iteration: 25\n",
      "Change: 0.0015374261408134526\n",
      "Iteration: 26\n",
      "Change: 0.0011674567464372565\n",
      "Iteration: 27\n",
      "Change: 0.0008947058808879138\n",
      "Iteration: 28\n",
      "Change: 0.0006861255278465261\n",
      "Iteration: 29\n",
      "Change: 0.0004989823240006686\n",
      "Iteration: 30\n",
      "Change: 0.00041206759257197967\n",
      "Iteration: 31\n",
      "Change: 0.00033487154057978974\n",
      "Iteration: 32\n",
      "Change: 0.00023792723158513884\n",
      "Iteration: 33\n",
      "Change: 0.00020223814684733332\n",
      "Iteration: 34\n",
      "Change: 0.00016733900338630758\n",
      "Iteration: 35\n",
      "Change: 0.000117885309362048\n",
      "Iteration: 36\n",
      "Change: 0.00010020251295775329\n",
      "Iteration: 37\n",
      "Change: 7.97955552407914e-05\n",
      "Iteration: 38\n",
      "Change: 5.616382871492798e-05\n",
      "Iteration: 39\n",
      "Change: 4.7396143949635094e-05\n",
      "Iteration: 40\n",
      "Change: 3.633235435465676e-05\n",
      "Iteration: 41\n",
      "Change: 2.7384050012568828e-05\n",
      "Iteration: 42\n",
      "Change: 2.1398933203964354e-05\n",
      "Iteration: 43\n",
      "Change: 1.5734140862394552e-05\n",
      "Iteration: 44\n",
      "Change: 1.275194338951069e-05\n",
      "Iteration: 45\n",
      "Change: 1.0046004543212694e-05\n",
      "Iteration: 46\n",
      "Change: 7.15337406470562e-06\n",
      "Iteration: 47\n",
      "Change: 6.080367955046961e-06\n",
      "Iteration: 48\n",
      "Change: 5.079432728261057e-06\n",
      "Iteration: 49\n",
      "Change: 3.585340177747476e-06\n",
      "Iteration: 50\n",
      "Change: 3.0475391511464167e-06\n",
      "Iteration: 51\n",
      "Change: 2.4487735963141244e-06\n",
      "Iteration: 52\n",
      "Change: 1.714483050752058e-06\n",
      "Iteration: 53\n",
      "Change: 1.4573105932003116e-06\n",
      "Iteration: 54\n",
      "Change: 1.1275123604492787e-06\n",
      "Iteration: 55\n",
      "Change: 8.359674851521337e-07\n",
      "Iteration: 56\n",
      "Change: 6.654658692151205e-07\n",
      "Iteration: 57\n",
      "Change: 4.944639108994675e-07\n",
      "Iteration: 58\n",
      "Change: 3.935674876831552e-07\n",
      "Iteration: 59\n",
      "Change: 3.0045564786140844e-07\n",
      "Iteration: 60\n",
      "Change: 2.1443192876891004e-07\n",
      "Iteration: 61\n",
      "Change: 1.8226713946467576e-07\n",
      "Iteration: 62\n",
      "Change: 1.5376855486137764e-07\n",
      "Iteration: 63\n",
      "Change: 1.0875527026166232e-07\n",
      "Iteration: 64\n",
      "Change: 9.244197976543411e-08\n",
      "The final page rank is\n",
      "A :  0.29633860747535035\n",
      "B :  0.11396259235540213\n",
      "C :  0.11396259235540213\n",
      "D :  0.16239669591744854\n",
      "E :  0.31333951189639714\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dg = digraph()\n",
    "\n",
    "    dg.add_nodes([\"A\", \"B\", \"C\", \"D\", \"E\"])\n",
    "\n",
    "    dg.add_edge((\"A\", \"B\"))\n",
    "    dg.add_edge((\"A\", \"C\"))\n",
    "    dg.add_edge((\"A\", \"D\"))\n",
    "    dg.add_edge((\"B\", \"D\"))\n",
    "    dg.add_edge((\"C\", \"E\"))\n",
    "    dg.add_edge((\"D\", \"E\"))\n",
    "    dg.add_edge((\"B\", \"E\"))\n",
    "    dg.add_edge((\"E\", \"A\"))\n",
    "\n",
    "    pr = PRMapReduce(dg)\n",
    "    page_ranks = pr.page_rank()\n",
    "\n",
    "    print(\"The final page rank is\")\n",
    "    for key, value in page_ranks.items():\n",
    "        print(key + \" : \", value[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
