{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-1 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 14 columns):\n",
      "x1     20 non-null int64\n",
      "x2     20 non-null float64\n",
      "x3     20 non-null float64\n",
      "x4     20 non-null float64\n",
      "x5     20 non-null float64\n",
      "x6     20 non-null int64\n",
      "x7     20 non-null float64\n",
      "x8     20 non-null float64\n",
      "x9     20 non-null float64\n",
      "x10    20 non-null float64\n",
      "x11    20 non-null float64\n",
      "x12    20 non-null float64\n",
      "x13    20 non-null int64\n",
      "y      20 non-null float64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 2.3 KB\n"
     ]
    }
   ],
   "source": [
    "inputfile = path + '/data/data1.csv'\n",
    "data1 = pd.read_csv(inputfile)\n",
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3831732</td>\n",
       "      <td>181.54</td>\n",
       "      <td>448.19</td>\n",
       "      <td>7571.00</td>\n",
       "      <td>6212.70</td>\n",
       "      <td>6370241</td>\n",
       "      <td>525.71</td>\n",
       "      <td>985.31</td>\n",
       "      <td>60.62</td>\n",
       "      <td>65.66</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.029</td>\n",
       "      <td>5321</td>\n",
       "      <td>64.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3913824</td>\n",
       "      <td>214.63</td>\n",
       "      <td>549.97</td>\n",
       "      <td>9038.16</td>\n",
       "      <td>7601.73</td>\n",
       "      <td>6467115</td>\n",
       "      <td>618.25</td>\n",
       "      <td>1259.20</td>\n",
       "      <td>73.46</td>\n",
       "      <td>95.46</td>\n",
       "      <td>113.5</td>\n",
       "      <td>1.051</td>\n",
       "      <td>6529</td>\n",
       "      <td>99.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3928907</td>\n",
       "      <td>239.56</td>\n",
       "      <td>686.44</td>\n",
       "      <td>9905.31</td>\n",
       "      <td>8092.82</td>\n",
       "      <td>6560508</td>\n",
       "      <td>638.94</td>\n",
       "      <td>1468.06</td>\n",
       "      <td>81.16</td>\n",
       "      <td>81.16</td>\n",
       "      <td>108.2</td>\n",
       "      <td>1.064</td>\n",
       "      <td>7008</td>\n",
       "      <td>88.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4282130</td>\n",
       "      <td>261.58</td>\n",
       "      <td>802.59</td>\n",
       "      <td>10444.60</td>\n",
       "      <td>8767.98</td>\n",
       "      <td>6664862</td>\n",
       "      <td>656.58</td>\n",
       "      <td>1678.12</td>\n",
       "      <td>85.72</td>\n",
       "      <td>91.70</td>\n",
       "      <td>102.2</td>\n",
       "      <td>1.092</td>\n",
       "      <td>7694</td>\n",
       "      <td>106.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4453911</td>\n",
       "      <td>283.14</td>\n",
       "      <td>904.57</td>\n",
       "      <td>11255.70</td>\n",
       "      <td>9422.33</td>\n",
       "      <td>6741400</td>\n",
       "      <td>758.83</td>\n",
       "      <td>1893.52</td>\n",
       "      <td>88.88</td>\n",
       "      <td>114.61</td>\n",
       "      <td>97.7</td>\n",
       "      <td>1.200</td>\n",
       "      <td>8027</td>\n",
       "      <td>137.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x1      x2      x3        x4       x5       x6      x7       x8  \\\n",
       "0  3831732  181.54  448.19   7571.00  6212.70  6370241  525.71   985.31   \n",
       "1  3913824  214.63  549.97   9038.16  7601.73  6467115  618.25  1259.20   \n",
       "2  3928907  239.56  686.44   9905.31  8092.82  6560508  638.94  1468.06   \n",
       "3  4282130  261.58  802.59  10444.60  8767.98  6664862  656.58  1678.12   \n",
       "4  4453911  283.14  904.57  11255.70  9422.33  6741400  758.83  1893.52   \n",
       "\n",
       "      x9     x10    x11    x12   x13       y  \n",
       "0  60.62   65.66  120.0  1.029  5321   64.87  \n",
       "1  73.46   95.46  113.5  1.051  6529   99.75  \n",
       "2  81.16   81.16  108.2  1.064  7008   88.11  \n",
       "3  85.72   91.70  102.2  1.092  7694  106.07  \n",
       "4  88.88  114.61   97.7  1.200  8027  137.32  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-1-1 描述性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>5579519.95</td>\n",
       "      <td>1262194.72</td>\n",
       "      <td>3831732.00</td>\n",
       "      <td>4525116.75</td>\n",
       "      <td>5308896.50</td>\n",
       "      <td>6594657.50</td>\n",
       "      <td>7599295.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>765.04</td>\n",
       "      <td>595.70</td>\n",
       "      <td>181.54</td>\n",
       "      <td>302.22</td>\n",
       "      <td>565.94</td>\n",
       "      <td>1033.54</td>\n",
       "      <td>2110.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2370.83</td>\n",
       "      <td>1919.17</td>\n",
       "      <td>448.19</td>\n",
       "      <td>976.66</td>\n",
       "      <td>1586.02</td>\n",
       "      <td>3294.48</td>\n",
       "      <td>6882.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>19644.69</td>\n",
       "      <td>10203.02</td>\n",
       "      <td>7571.00</td>\n",
       "      <td>11827.81</td>\n",
       "      <td>15943.38</td>\n",
       "      <td>25889.94</td>\n",
       "      <td>42049.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>20.0</td>\n",
       "      <td>15870.95</td>\n",
       "      <td>8199.77</td>\n",
       "      <td>6212.70</td>\n",
       "      <td>9669.16</td>\n",
       "      <td>12345.70</td>\n",
       "      <td>21332.18</td>\n",
       "      <td>33156.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x6</th>\n",
       "      <td>20.0</td>\n",
       "      <td>7350513.60</td>\n",
       "      <td>621341.85</td>\n",
       "      <td>6370241.00</td>\n",
       "      <td>6822868.00</td>\n",
       "      <td>7314304.00</td>\n",
       "      <td>7867809.75</td>\n",
       "      <td>8323096.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x7</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1712.24</td>\n",
       "      <td>1184.71</td>\n",
       "      <td>525.71</td>\n",
       "      <td>848.40</td>\n",
       "      <td>1262.05</td>\n",
       "      <td>2244.12</td>\n",
       "      <td>4454.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x8</th>\n",
       "      <td>20.0</td>\n",
       "      <td>5705.80</td>\n",
       "      <td>4478.40</td>\n",
       "      <td>985.31</td>\n",
       "      <td>2077.76</td>\n",
       "      <td>4104.58</td>\n",
       "      <td>8500.09</td>\n",
       "      <td>15420.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x9</th>\n",
       "      <td>20.0</td>\n",
       "      <td>129.49</td>\n",
       "      <td>50.51</td>\n",
       "      <td>60.62</td>\n",
       "      <td>91.86</td>\n",
       "      <td>113.53</td>\n",
       "      <td>169.96</td>\n",
       "      <td>228.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x10</th>\n",
       "      <td>20.0</td>\n",
       "      <td>340.22</td>\n",
       "      <td>251.58</td>\n",
       "      <td>65.66</td>\n",
       "      <td>143.24</td>\n",
       "      <td>235.76</td>\n",
       "      <td>521.07</td>\n",
       "      <td>852.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x11</th>\n",
       "      <td>20.0</td>\n",
       "      <td>103.31</td>\n",
       "      <td>5.51</td>\n",
       "      <td>97.50</td>\n",
       "      <td>99.80</td>\n",
       "      <td>102.45</td>\n",
       "      <td>103.93</td>\n",
       "      <td>120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x12</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x13</th>\n",
       "      <td>20.0</td>\n",
       "      <td>17273.80</td>\n",
       "      <td>11109.19</td>\n",
       "      <td>5321.00</td>\n",
       "      <td>8418.50</td>\n",
       "      <td>13267.00</td>\n",
       "      <td>22633.00</td>\n",
       "      <td>41972.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>20.0</td>\n",
       "      <td>618.08</td>\n",
       "      <td>609.25</td>\n",
       "      <td>64.87</td>\n",
       "      <td>175.44</td>\n",
       "      <td>319.50</td>\n",
       "      <td>909.27</td>\n",
       "      <td>2088.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count        mean         std         min         25%         50%  \\\n",
       "x1    20.0  5579519.95  1262194.72  3831732.00  4525116.75  5308896.50   \n",
       "x2    20.0      765.04      595.70      181.54      302.22      565.94   \n",
       "x3    20.0     2370.83     1919.17      448.19      976.66     1586.02   \n",
       "x4    20.0    19644.69    10203.02     7571.00    11827.81    15943.38   \n",
       "x5    20.0    15870.95     8199.77     6212.70     9669.16    12345.70   \n",
       "x6    20.0  7350513.60   621341.85  6370241.00  6822868.00  7314304.00   \n",
       "x7    20.0     1712.24     1184.71      525.71      848.40     1262.05   \n",
       "x8    20.0     5705.80     4478.40      985.31     2077.76     4104.58   \n",
       "x9    20.0      129.49       50.51       60.62       91.86      113.53   \n",
       "x10   20.0      340.22      251.58       65.66      143.24      235.76   \n",
       "x11   20.0      103.31        5.51       97.50       99.80      102.45   \n",
       "x12   20.0        1.42        0.25        1.03        1.20        1.46   \n",
       "x13   20.0    17273.80    11109.19     5321.00     8418.50    13267.00   \n",
       "y     20.0      618.08      609.25       64.87      175.44      319.50   \n",
       "\n",
       "            75%         max  \n",
       "x1   6594657.50  7599295.00  \n",
       "x2      1033.54     2110.78  \n",
       "x3      3294.48     6882.85  \n",
       "x4     25889.94    42049.14  \n",
       "x5     21332.18    33156.83  \n",
       "x6   7867809.75  8323096.00  \n",
       "x7      2244.12     4454.55  \n",
       "x8      8500.09    15420.14  \n",
       "x9       169.96      228.46  \n",
       "x10      521.07      852.56  \n",
       "x11      103.93      120.00  \n",
       "x12        1.58        1.91  \n",
       "x13    22633.00    41972.00  \n",
       "y        909.27     2088.14  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = pd.DataFrame(data1.describe()).T\n",
    "# 保留两位小数\n",
    "np.round(r, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-1-2 相关分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x6</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x7</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x8</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x9</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x10</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x11</th>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x12</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x13</th>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x1    x2    x3    x4    x5    x6    x7    x8    x9   x10   x11   x12  \\\n",
       "x1   1.00  0.95  0.95  0.97  0.97  0.99  0.95  0.97  0.98  0.98 -0.29  0.94   \n",
       "x2   0.95  1.00  1.00  0.99  0.99  0.92  0.99  0.99  0.98  0.98 -0.13  0.89   \n",
       "x3   0.95  1.00  1.00  0.99  0.99  0.92  1.00  0.99  0.98  0.99 -0.15  0.89   \n",
       "x4   0.97  0.99  0.99  1.00  1.00  0.95  0.99  1.00  0.99  1.00 -0.19  0.91   \n",
       "x5   0.97  0.99  0.99  1.00  1.00  0.95  0.99  1.00  0.99  1.00 -0.18  0.90   \n",
       "x6   0.99  0.92  0.92  0.95  0.95  1.00  0.93  0.95  0.97  0.96 -0.34  0.95   \n",
       "x7   0.95  0.99  1.00  0.99  0.99  0.93  1.00  0.99  0.98  0.99 -0.15  0.89   \n",
       "x8   0.97  0.99  0.99  1.00  1.00  0.95  0.99  1.00  0.99  1.00 -0.15  0.90   \n",
       "x9   0.98  0.98  0.98  0.99  0.99  0.97  0.98  0.99  1.00  0.99 -0.23  0.91   \n",
       "x10  0.98  0.98  0.99  1.00  1.00  0.96  0.99  1.00  0.99  1.00 -0.17  0.90   \n",
       "x11 -0.29 -0.13 -0.15 -0.19 -0.18 -0.34 -0.15 -0.15 -0.23 -0.17  1.00 -0.43   \n",
       "x12  0.94  0.89  0.89  0.91  0.90  0.95  0.89  0.90  0.91  0.90 -0.43  1.00   \n",
       "x13  0.96  1.00  1.00  1.00  0.99  0.94  1.00  1.00  0.99  0.99 -0.16  0.90   \n",
       "y    0.94  0.98  0.99  0.99  0.99  0.91  0.99  0.99  0.98  0.99 -0.12  0.87   \n",
       "\n",
       "      x13     y  \n",
       "x1   0.96  0.94  \n",
       "x2   1.00  0.98  \n",
       "x3   1.00  0.99  \n",
       "x4   1.00  0.99  \n",
       "x5   0.99  0.99  \n",
       "x6   0.94  0.91  \n",
       "x7   1.00  0.99  \n",
       "x8   1.00  0.99  \n",
       "x9   0.99  0.98  \n",
       "x10  0.99  0.99  \n",
       "x11 -0.16 -0.12  \n",
       "x12  0.90  0.87  \n",
       "x13  1.00  0.99  \n",
       "y    0.99  1.00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算相关系数矩阵\n",
    "np.round(data1.corr(method = 'pearson'), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-2 模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-2-1 Lasso变量选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.07005680e-04,  2.02781609e-01,  8.56717095e-03, -3.51645774e-03,\n",
       "        1.83548359e-04, -1.91284850e-04,  1.17122737e-01, -6.50762881e-03,\n",
       "       -4.30958088e-01,  5.18365942e-02,  1.06661718e+01, -7.06390827e+01,\n",
       "        3.75255292e-03])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model = Lasso(tol = 1)\n",
    "model.fit(data1.iloc[:, 0:13], data1['y'])\n",
    "model.coef_    # 各个特征的系数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-2-2 地方财政收入灰色预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GM11(x0):\n",
    "    # 1-AGO序列, 累计求和\n",
    "    x1 = np.cumsum(x0)\n",
    "    # 紧邻均值（MEAN）生成序列\n",
    "    z1 = (x1[:-1] + x1[1:]) / 2.0\n",
    "    z1 = z1.reshape(len(z1), 1)\n",
    "    B = np.append(-z1, np.ones_like(z1), axis = 1)\n",
    "    Yn = x0[1:].reshape((len(x0) - 1, 1))\n",
    "    # 矩阵计算，计算参数\n",
    "    [[a], [b]] = np.dot(np.dot(np.linalg.inv(np.dot(B.T, B)), B.T), Yn)\n",
    "    # 还原值\n",
    "\n",
    "    f = lambda k: (x0[0] - b / a) * np.exp(-a * (k - 1)) - (x0[0] - b / a) * np.exp(- a * (k - 2))\n",
    "\n",
    "    delta = np.abs(x0 - np.array([f(i) for i in range(1, len(x0) + 1)]))\n",
    "    C = delta.std() / x0.std()\n",
    "    P = 1.0 * (np.abs(delta - delta.mean()) < 0.6745 * x0.std()).sum() / len(x0)\n",
    "    \n",
    "    # 灰度预测函数、a、b、首项、方差比、小残差概率\n",
    "    return f, a, b, x0[0], C, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              x1       x2       x3        x4        x5       x7        y\n",
      "1994  3831732.00   181.54   448.19   7571.00   6212.70   525.71    64.87\n",
      "1995  3913824.00   214.63   549.97   9038.16   7601.73   618.25    99.75\n",
      "1996  3928907.00   239.56   686.44   9905.31   8092.82   638.94    88.11\n",
      "1997  4282130.00   261.58   802.59  10444.60   8767.98   656.58   106.07\n",
      "1998  4453911.00   283.14   904.57  11255.70   9422.33   758.83   137.32\n",
      "1999  4548852.00   308.58  1000.69  12018.52   9751.44   878.26   188.14\n",
      "2000  4962579.00   348.09  1121.13  13966.53  11349.47   923.67   219.91\n",
      "2001  5029338.00   387.81  1248.29  14694.00  11467.35   978.21   271.91\n",
      "2002  5070216.00   453.49  1370.68  13380.47  10671.78  1009.24   269.10\n",
      "2003  5210706.00   533.55  1494.27  15002.59  11570.58  1175.17   300.55\n",
      "2004  5407087.00   598.33  1677.77  16884.16  13120.83  1348.93   338.45\n",
      "2005  5744550.00   665.32  1905.84  18287.24  14468.24  1519.16   408.86\n",
      "2006  5994973.00   738.97  2199.14  19850.66  15444.93  1696.38   476.72\n",
      "2007  6236312.00   877.07  2624.24  22469.22  18951.32  1863.34   838.99\n",
      "2008  6529045.00  1005.37  3187.39  25316.72  20835.95  2105.54   843.14\n",
      "2009  6791495.00  1118.03  3615.77  27609.59  22820.89  2659.85  1107.67\n",
      "2010  7110695.00  1304.48  4476.38  30658.49  25011.61  3263.57  1399.16\n",
      "2011  7431755.00  1700.87  5243.03  34438.08  28209.74  3412.21  1535.14\n",
      "2012  7512997.00  1969.51  5977.27  38053.52  30490.44  3758.39  1579.68\n",
      "2013  7599295.00  2110.78  6882.85  42049.14  33156.83  4454.55  2088.14\n",
      "2014  8142148.24  2239.29  7042.31  43611.84  35046.63  4600.40      NaN\n",
      "2015  8460489.28  2581.14  8166.92  47792.22  38384.22  5214.78      NaN\n"
     ]
    }
   ],
   "source": [
    "outputfile_GM11 = path + '/tmp/data1_GM11.xls'    # 灰色预测后保存路径\n",
    "data1.index = range(1994, 2014)\n",
    "\n",
    "data1.loc[2014] = None\n",
    "data1.loc[2015] = None\n",
    "feature_lst = ['x1', 'x2', 'x3', 'x4', 'x5', 'x7']\n",
    "for i in feature_lst:\n",
    "    f = GM11(data1[i][list(range(1994, 2014))].as_matrix())[0]\n",
    "    # 2014年预测结果\n",
    "    data1[i][2014] = f(len(data1) - 1)\n",
    "    # 2015年预测结果\n",
    "    data1[i][2015] = f(len(data1))\n",
    "    # 保留两位小数\n",
    "    data1[i] = data1[i].round(2)\n",
    "\n",
    "print(data1[feature_lst + ['y']])\n",
    "data1[feature_lst + ['y']].to_excel(outputfile_GM11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-2-3 地方财政收入神经网络预测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "outputfile_LM = path + '/data/revenue.xls'\n",
    "modelfile = path + '/tmp/net-revenue.model'\n",
    "\n",
    "data_LM = data1[feature_lst + ['y']]\n",
    "data_train = data_LM.loc[range(1994, 2014)].copy()    # 取2014年前的数据\n",
    "data_mean = data_train.mean()\n",
    "data_std = data_train.std()\n",
    "# 数据标准化\n",
    "data_train = (data_train - data_mean) / data_std\n",
    "    \n",
    "# 特征数据\n",
    "x_train = data_train[feature_lst].as_matrix()\n",
    "# 标签数据\n",
    "y_train = data_train['y'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 1.0059\n",
      "Epoch 2/10000\n",
      "20/20 [==============================] - 0s 477us/step - loss: 0.9748\n",
      "Epoch 3/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.9418\n",
      "Epoch 4/10000\n",
      "20/20 [==============================] - 0s 574us/step - loss: 0.9133\n",
      "Epoch 5/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.8845\n",
      "Epoch 6/10000\n",
      "20/20 [==============================] - 0s 374us/step - loss: 0.8574\n",
      "Epoch 7/10000\n",
      "20/20 [==============================] - 0s 977us/step - loss: 0.8307\n",
      "Epoch 8/10000\n",
      "20/20 [==============================] - 0s 677us/step - loss: 0.8040\n",
      "Epoch 9/10000\n",
      "20/20 [==============================] - 0s 650us/step - loss: 0.7790\n",
      "Epoch 10/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.7542\n",
      "Epoch 11/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.7304\n",
      "Epoch 12/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.7084\n",
      "Epoch 13/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.6869\n",
      "Epoch 14/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.6670\n",
      "Epoch 15/10000\n",
      "20/20 [==============================] - 0s 675us/step - loss: 0.6463\n",
      "Epoch 16/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.6263\n",
      "Epoch 17/10000\n",
      "20/20 [==============================] - 0s 375us/step - loss: 0.6083\n",
      "Epoch 18/10000\n",
      "20/20 [==============================] - 0s 725us/step - loss: 0.5894\n",
      "Epoch 19/10000\n",
      "20/20 [==============================] - 0s 625us/step - loss: 0.5722\n",
      "Epoch 20/10000\n",
      "20/20 [==============================] - 0s 600us/step - loss: 0.5545\n",
      "Epoch 21/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.5364\n",
      "Epoch 22/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.5194\n",
      "Epoch 23/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.5025\n",
      "Epoch 24/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.4851\n",
      "Epoch 25/10000\n",
      "20/20 [==============================] - 0s 452us/step - loss: 0.4686\n",
      "Epoch 26/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.4523\n",
      "Epoch 27/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.4355\n",
      "Epoch 28/10000\n",
      "20/20 [==============================] - 0s 575us/step - loss: 0.4196\n",
      "Epoch 29/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.4030\n",
      "Epoch 30/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.3887\n",
      "Epoch 31/10000\n",
      "20/20 [==============================] - 0s 650us/step - loss: 0.3727\n",
      "Epoch 32/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.3562\n",
      "Epoch 33/10000\n",
      "20/20 [==============================] - 0s 425us/step - loss: 0.3422\n",
      "Epoch 34/10000\n",
      "20/20 [==============================] - 0s 700us/step - loss: 0.3266\n",
      "Epoch 35/10000\n",
      "20/20 [==============================] - 0s 700us/step - loss: 0.3120\n",
      "Epoch 36/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.2982\n",
      "Epoch 37/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.2841\n",
      "Epoch 38/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.2709\n",
      "Epoch 39/10000\n",
      "20/20 [==============================] - 0s 425us/step - loss: 0.2578\n",
      "Epoch 40/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.2447\n",
      "Epoch 41/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.2296\n",
      "Epoch 42/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.2170\n",
      "Epoch 43/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.2024\n",
      "Epoch 44/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.1895\n",
      "Epoch 45/10000\n",
      "20/20 [==============================] - 0s 650us/step - loss: 0.1748\n",
      "Epoch 46/10000\n",
      "20/20 [==============================] - 0s 425us/step - loss: 0.1632\n",
      "Epoch 47/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.1501\n",
      "Epoch 48/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.1380\n",
      "Epoch 49/10000\n",
      "20/20 [==============================] - 0s 800us/step - loss: 0.1253\n",
      "Epoch 50/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.1144\n",
      "Epoch 51/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.1044\n",
      "Epoch 52/10000\n",
      "20/20 [==============================] - 0s 350us/step - loss: 0.0949\n",
      "Epoch 53/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0850\n",
      "Epoch 54/10000\n",
      "20/20 [==============================] - 0s 725us/step - loss: 0.0769\n",
      "Epoch 55/10000\n",
      "20/20 [==============================] - 0s 350us/step - loss: 0.0695\n",
      "Epoch 56/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0631\n",
      "Epoch 57/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0573\n",
      "Epoch 58/10000\n",
      "20/20 [==============================] - 0s 375us/step - loss: 0.0521\n",
      "Epoch 59/10000\n",
      "20/20 [==============================] - 0s 375us/step - loss: 0.0469\n",
      "Epoch 60/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0434\n",
      "Epoch 61/10000\n",
      "20/20 [==============================] - 0s 425us/step - loss: 0.0396\n",
      "Epoch 62/10000\n",
      "20/20 [==============================] - 0s 975us/step - loss: 0.0364\n",
      "Epoch 63/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0337\n",
      "Epoch 64/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0314\n",
      "Epoch 65/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0293\n",
      "Epoch 66/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0277\n",
      "Epoch 67/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0260\n",
      "Epoch 68/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0250\n",
      "Epoch 69/10000\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0238\n",
      "Epoch 70/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0229\n",
      "Epoch 71/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0221\n",
      "Epoch 72/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0214\n",
      "Epoch 73/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0209\n",
      "Epoch 74/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0205\n",
      "Epoch 75/10000\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0202\n",
      "Epoch 76/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0199\n",
      "Epoch 77/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0195\n",
      "Epoch 78/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0193\n",
      "Epoch 79/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0191\n",
      "Epoch 80/10000\n",
      "20/20 [==============================] - 0s 375us/step - loss: 0.0189\n",
      "Epoch 81/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0186\n",
      "Epoch 82/10000\n",
      "20/20 [==============================] - 0s 575us/step - loss: 0.0186\n",
      "Epoch 83/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0183\n",
      "Epoch 84/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0184\n",
      "Epoch 85/10000\n",
      "20/20 [==============================] - 0s 425us/step - loss: 0.0183\n",
      "Epoch 86/10000\n",
      "20/20 [==============================] - 0s 575us/step - loss: 0.0181\n",
      "Epoch 87/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0181\n",
      "Epoch 88/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0180\n",
      "Epoch 89/10000\n",
      "20/20 [==============================] - 0s 575us/step - loss: 0.0179\n",
      "Epoch 90/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0178\n",
      "Epoch 91/10000\n",
      "20/20 [==============================] - 0s 452us/step - loss: 0.0177\n",
      "Epoch 92/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0176\n",
      "Epoch 93/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0176\n",
      "Epoch 94/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0175\n",
      "Epoch 95/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0174\n",
      "Epoch 96/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0173\n",
      "Epoch 97/10000\n",
      "20/20 [==============================] - 0s 449us/step - loss: 0.0172\n",
      "Epoch 98/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0172\n",
      "Epoch 99/10000\n",
      "20/20 [==============================] - 0s 425us/step - loss: 0.0170\n",
      "Epoch 100/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0169\n",
      "Epoch 101/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0169\n",
      "Epoch 102/10000\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0168\n",
      "Epoch 103/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0167\n",
      "Epoch 104/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0168\n",
      "Epoch 105/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0166\n",
      "Epoch 106/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0166\n",
      "Epoch 107/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0165\n",
      "Epoch 108/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0164\n",
      "Epoch 109/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0164\n",
      "Epoch 110/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0163\n",
      "Epoch 111/10000\n",
      "20/20 [==============================] - 0s 425us/step - loss: 0.0162\n",
      "Epoch 112/10000\n",
      "20/20 [==============================] - 0s 477us/step - loss: 0.0162\n",
      "Epoch 113/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0161\n",
      "Epoch 114/10000\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.0161\n",
      "Epoch 115/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0160\n",
      "Epoch 116/10000\n",
      "20/20 [==============================] - 0s 425us/step - loss: 0.0159\n",
      "Epoch 117/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0158\n",
      "Epoch 118/10000\n",
      "20/20 [==============================] - 0s 625us/step - loss: 0.0158\n",
      "Epoch 119/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0157\n",
      "Epoch 120/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0156\n",
      "Epoch 121/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0156\n",
      "Epoch 122/10000\n",
      "20/20 [==============================] - 0s 524us/step - loss: 0.0155\n",
      "Epoch 123/10000\n",
      "20/20 [==============================] - 0s 750us/step - loss: 0.0155\n",
      "Epoch 124/10000\n",
      "20/20 [==============================] - 0s 650us/step - loss: 0.0155\n",
      "Epoch 125/10000\n",
      "20/20 [==============================] - 0s 775us/step - loss: 0.0154\n",
      "Epoch 126/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0154\n",
      "Epoch 127/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.740565). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "D:\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.370282). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/10000\n",
      "20/20 [==============================] - 0s 850us/step - loss: 0.0153\n",
      "Epoch 129/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0152\n",
      "Epoch 130/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0151\n",
      "Epoch 131/10000\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 132/10000\n",
      "20/20 [==============================] - 0s 700us/step - loss: 0.0150\n",
      "Epoch 133/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0149\n",
      "Epoch 134/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0149\n",
      "Epoch 135/10000\n",
      "20/20 [==============================] - 0s 300us/step - loss: 0.0148\n",
      "Epoch 136/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0148\n",
      "Epoch 137/10000\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 138/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0149\n",
      "Epoch 139/10000\n",
      "20/20 [==============================] - 0s 600us/step - loss: 0.0147\n",
      "Epoch 140/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0147\n",
      "Epoch 141/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0147\n",
      "Epoch 142/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0147\n",
      "Epoch 143/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0147\n",
      "Epoch 144/10000\n",
      "20/20 [==============================] - 0s 613us/step - loss: 0.0146\n",
      "Epoch 145/10000\n",
      "20/20 [==============================] - 0s 600us/step - loss: 0.0147\n",
      "Epoch 146/10000\n",
      "20/20 [==============================] - 0s 575us/step - loss: 0.0146\n",
      "Epoch 147/10000\n",
      "20/20 [==============================] - 0s 650us/step - loss: 0.0146\n",
      "Epoch 148/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0146\n",
      "Epoch 149/10000\n",
      "20/20 [==============================] - 0s 627us/step - loss: 0.0145\n",
      "Epoch 150/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0145\n",
      "Epoch 151/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0143\n",
      "Epoch 152/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0143\n",
      "Epoch 153/10000\n",
      "20/20 [==============================] - 0s 675us/step - loss: 0.0143\n",
      "Epoch 154/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0142\n",
      "Epoch 155/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0141\n",
      "Epoch 156/10000\n",
      "20/20 [==============================] - 0s 427us/step - loss: 0.0140\n",
      "Epoch 157/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0140\n",
      "Epoch 158/10000\n",
      "20/20 [==============================] - 0s 399us/step - loss: 0.0139\n",
      "Epoch 159/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0138\n",
      "Epoch 160/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0138\n",
      "Epoch 161/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0137\n",
      "Epoch 162/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0137\n",
      "Epoch 163/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0136\n",
      "Epoch 164/10000\n",
      "20/20 [==============================] - 0s 426us/step - loss: 0.0137\n",
      "Epoch 165/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0136\n",
      "Epoch 166/10000\n",
      "20/20 [==============================] - 0s 575us/step - loss: 0.0136\n",
      "Epoch 167/10000\n",
      "20/20 [==============================] - 0s 474us/step - loss: 0.0135\n",
      "Epoch 168/10000\n",
      "20/20 [==============================] - 0s 425us/step - loss: 0.0136\n",
      "Epoch 169/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0136\n",
      "Epoch 170/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0136\n",
      "Epoch 171/10000\n",
      "20/20 [==============================] - 0s 425us/step - loss: 0.0136\n",
      "Epoch 172/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0136\n",
      "Epoch 173/10000\n",
      "20/20 [==============================] - 0s 600us/step - loss: 0.0134\n",
      "Epoch 174/10000\n",
      "20/20 [==============================] - 0s 401us/step - loss: 0.0134\n",
      "Epoch 175/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0134\n",
      "Epoch 176/10000\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 0.0133\n",
      "Epoch 177/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0133\n",
      "Epoch 178/10000\n",
      "20/20 [==============================] - 0s 674us/step - loss: 0.0132\n",
      "Epoch 179/10000\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0132\n",
      "Epoch 180/10000\n",
      "20/20 [==============================] - 0s 650us/step - loss: 0.0132\n",
      "Epoch 181/10000\n",
      "20/20 [==============================] - 0s 526us/step - loss: 0.0131\n",
      "Epoch 182/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0132\n",
      "Epoch 183/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0131\n",
      "Epoch 184/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0130\n",
      "Epoch 185/10000\n",
      "20/20 [==============================] - 0s 575us/step - loss: 0.0130\n",
      "Epoch 186/10000\n",
      "20/20 [==============================] - 0s 950us/step - loss: 0.0130\n",
      "Epoch 187/10000\n",
      "16/20 [=======================>......] - ETA: 0s - loss: 0.0118"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (1.428190). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "D:\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.714334). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 500us/step - loss: 0.0129\n",
      "Epoch 188/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0129\n",
      "Epoch 189/10000\n",
      "20/20 [==============================] - 0s 575us/step - loss: 0.0129\n",
      "Epoch 190/10000\n",
      "20/20 [==============================] - 0s 575us/step - loss: 0.0129\n",
      "Epoch 191/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0129\n",
      "Epoch 192/10000\n",
      "20/20 [==============================] - 0s 527us/step - loss: 0.0130\n",
      "Epoch 193/10000\n",
      "20/20 [==============================] - 0s 474us/step - loss: 0.0132\n",
      "Epoch 194/10000\n",
      "20/20 [==============================] - 0s 424us/step - loss: 0.0131\n",
      "Epoch 195/10000\n",
      "20/20 [==============================] - 0s 477us/step - loss: 0.0130\n",
      "Epoch 196/10000\n",
      "20/20 [==============================] - 0s 474us/step - loss: 0.0130\n",
      "Epoch 197/10000\n",
      "20/20 [==============================] - 0s 474us/step - loss: 0.0130\n",
      "Epoch 198/10000\n",
      "20/20 [==============================] - 0s 524us/step - loss: 0.0129\n",
      "Epoch 199/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0129\n",
      "Epoch 200/10000\n",
      "20/20 [==============================] - 0s 700us/step - loss: 0.0129\n",
      "Epoch 201/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0132\n",
      "Epoch 202/10000\n",
      "20/20 [==============================] - 0s 800us/step - loss: 0.0131\n",
      "Epoch 203/10000\n",
      "20/20 [==============================] - 0s 474us/step - loss: 0.0130\n",
      "Epoch 204/10000\n",
      "20/20 [==============================] - 0s 950us/step - loss: 0.0130\n",
      "Epoch 205/10000\n",
      "20/20 [==============================] - 0s 575us/step - loss: 0.0128\n",
      "Epoch 206/10000\n",
      "20/20 [==============================] - 0s 700us/step - loss: 0.0128\n",
      "Epoch 207/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0127\n",
      "Epoch 208/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0125\n",
      "Epoch 209/10000\n",
      "20/20 [==============================] - 0s 650us/step - loss: 0.0127\n",
      "Epoch 210/10000\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0125\n",
      "Epoch 211/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0126\n",
      "Epoch 212/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0125\n",
      "Epoch 213/10000\n",
      "20/20 [==============================] - 0s 653us/step - loss: 0.0125\n",
      "Epoch 214/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0125\n",
      "Epoch 215/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0126\n",
      "Epoch 216/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0125\n",
      "Epoch 217/10000\n",
      "20/20 [==============================] - 0s 600us/step - loss: 0.0125\n",
      "Epoch 218/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0124\n",
      "Epoch 219/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0124\n",
      "Epoch 220/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0124\n",
      "Epoch 221/10000\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0123\n",
      "Epoch 222/10000\n",
      "20/20 [==============================] - 0s 600us/step - loss: 0.0123\n",
      "Epoch 223/10000\n",
      "20/20 [==============================] - 0s 750us/step - loss: 0.0123\n",
      "Epoch 224/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0123\n",
      "Epoch 225/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0122\n",
      "Epoch 226/10000\n",
      "20/20 [==============================] - 0s 575us/step - loss: 0.0122\n",
      "Epoch 227/10000\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0122\n",
      "Epoch 228/10000\n",
      "20/20 [==============================] - 0s 425us/step - loss: 0.0122\n",
      "Epoch 229/10000\n",
      "20/20 [==============================] - 0s 700us/step - loss: 0.0122\n",
      "Epoch 230/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0122\n",
      "Epoch 231/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0121\n",
      "Epoch 232/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0121\n",
      "Epoch 233/10000\n",
      "20/20 [==============================] - 0s 800us/step - loss: 0.0121\n",
      "Epoch 234/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0121\n",
      "Epoch 235/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0121\n",
      "Epoch 236/10000\n",
      "20/20 [==============================] - 0s 375us/step - loss: 0.0121\n",
      "Epoch 237/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0121\n",
      "Epoch 238/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0121\n",
      "Epoch 239/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0121\n",
      "Epoch 240/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0121\n",
      "Epoch 241/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0120\n",
      "Epoch 242/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0120\n",
      "Epoch 243/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0120\n",
      "Epoch 244/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0121\n",
      "Epoch 245/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0121\n",
      "Epoch 246/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0120\n",
      "Epoch 247/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0120\n",
      "Epoch 248/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0120\n",
      "Epoch 249/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0120\n",
      "Epoch 250/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0120\n",
      "Epoch 251/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0120\n",
      "Epoch 252/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0120\n",
      "Epoch 253/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0119\n",
      "Epoch 254/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0119\n",
      "Epoch 255/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0119\n",
      "Epoch 256/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0120\n",
      "Epoch 257/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0119\n",
      "Epoch 258/10000\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0118\n",
      "Epoch 259/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0119\n",
      "Epoch 260/10000\n",
      "20/20 [==============================] - 0s 900us/step - loss: 0.0121\n",
      "Epoch 261/10000\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0120\n",
      "Epoch 262/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0120\n",
      "Epoch 263/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0121\n",
      "Epoch 264/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0120\n",
      "Epoch 265/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0120\n",
      "Epoch 266/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0119\n",
      "Epoch 267/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0119\n",
      "Epoch 268/10000\n",
      "20/20 [==============================] - 0s 600us/step - loss: 0.0121\n",
      "Epoch 269/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0120\n",
      "Epoch 270/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0120\n",
      "Epoch 271/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0119\n",
      "Epoch 272/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0118\n",
      "Epoch 273/10000\n",
      "20/20 [==============================] - 0s 350us/step - loss: 0.0119\n",
      "Epoch 274/10000\n",
      "20/20 [==============================] - 0s 350us/step - loss: 0.0118\n",
      "Epoch 275/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0117\n",
      "Epoch 276/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0117\n",
      "Epoch 277/10000\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0117\n",
      "Epoch 278/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0117\n",
      "Epoch 279/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0117\n",
      "Epoch 280/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0117\n",
      "Epoch 281/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0117\n",
      "Epoch 282/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0116\n",
      "Epoch 283/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0116\n",
      "Epoch 284/10000\n",
      "20/20 [==============================] - 0s 900us/step - loss: 0.0118\n",
      "Epoch 285/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0117\n",
      "Epoch 286/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0117\n",
      "Epoch 287/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0117\n",
      "Epoch 288/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0117\n",
      "Epoch 289/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0117\n",
      "Epoch 290/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0116\n",
      "Epoch 291/10000\n",
      "20/20 [==============================] - 0s 575us/step - loss: 0.0117\n",
      "Epoch 292/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0116\n",
      "Epoch 293/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0116\n",
      "Epoch 294/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0117\n",
      "Epoch 295/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0116\n",
      "Epoch 296/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0116\n",
      "Epoch 297/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0116\n",
      "Epoch 298/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0115\n",
      "Epoch 299/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0116\n",
      "Epoch 300/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0115\n",
      "Epoch 301/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0115\n",
      "Epoch 302/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0115\n",
      "Epoch 303/10000\n",
      "20/20 [==============================] - 0s 424us/step - loss: 0.0115\n",
      "Epoch 304/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0116\n",
      "Epoch 305/10000\n",
      "20/20 [==============================] - 0s 750us/step - loss: 0.0116\n",
      "Epoch 306/10000\n",
      "20/20 [==============================] - 0s 477us/step - loss: 0.0116\n",
      "Epoch 307/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0115\n",
      "Epoch 308/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0116\n",
      "Epoch 309/10000\n",
      "20/20 [==============================] - 0s 427us/step - loss: 0.0117\n",
      "Epoch 310/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0117\n",
      "Epoch 311/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0117\n",
      "Epoch 312/10000\n",
      "20/20 [==============================] - 0s 427us/step - loss: 0.0117\n",
      "Epoch 313/10000\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0117\n",
      "Epoch 314/10000\n",
      "20/20 [==============================] - 0s 426us/step - loss: 0.0117\n",
      "Epoch 315/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0117\n",
      "Epoch 316/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0116\n",
      "Epoch 317/10000\n",
      "20/20 [==============================] - 0s 426us/step - loss: 0.0115\n",
      "Epoch 318/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0115\n",
      "Epoch 319/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0114\n",
      "Epoch 320/10000\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.0113\n",
      "Epoch 321/10000\n",
      "20/20 [==============================] - 0s 474us/step - loss: 0.0113\n",
      "Epoch 322/10000\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.009 - 0s 450us/step - loss: 0.0114\n",
      "Epoch 323/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0113\n",
      "Epoch 324/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0113\n",
      "Epoch 325/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0113\n",
      "Epoch 326/10000\n",
      "20/20 [==============================] - 0s 775us/step - loss: 0.0113\n",
      "Epoch 327/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0113\n",
      "Epoch 328/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0113\n",
      "Epoch 329/10000\n",
      "20/20 [==============================] - 0s 575us/step - loss: 0.0112\n",
      "Epoch 330/10000\n",
      "20/20 [==============================] - 0s 551us/step - loss: 0.0112\n",
      "Epoch 331/10000\n",
      "20/20 [==============================] - 0s 675us/step - loss: 0.0112\n",
      "Epoch 332/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0112\n",
      "Epoch 333/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0114\n",
      "Epoch 334/10000\n",
      "20/20 [==============================] - 0s 677us/step - loss: 0.0113\n",
      "Epoch 335/10000\n",
      "20/20 [==============================] - 0s 577us/step - loss: 0.0113\n",
      "Epoch 336/10000\n",
      "20/20 [==============================] - 0s 800us/step - loss: 0.0113\n",
      "Epoch 337/10000\n",
      "20/20 [==============================] - 0s 350us/step - loss: 0.0113\n",
      "Epoch 338/10000\n",
      "20/20 [==============================] - 0s 426us/step - loss: 0.0114\n",
      "Epoch 339/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0114\n",
      "Epoch 340/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0116\n",
      "Epoch 341/10000\n",
      "20/20 [==============================] - 0s 474us/step - loss: 0.0117\n",
      "Epoch 342/10000\n",
      "20/20 [==============================] - 0s 974us/step - loss: 0.0118\n",
      "Epoch 343/10000\n",
      "20/20 [==============================] - 0s 424us/step - loss: 0.0117\n",
      "Epoch 344/10000\n",
      "20/20 [==============================] - 0s 476us/step - loss: 0.0116\n",
      "Epoch 345/10000\n",
      "20/20 [==============================] - 0s 377us/step - loss: 0.0113\n",
      "Epoch 346/10000\n",
      "20/20 [==============================] - 0s 600us/step - loss: 0.0113\n",
      "Epoch 347/10000\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0112\n",
      "Epoch 348/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0111\n",
      "Epoch 349/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0111\n",
      "Epoch 350/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0111\n",
      "Epoch 351/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0111\n",
      "Epoch 352/10000\n",
      "20/20 [==============================] - 0s 575us/step - loss: 0.0111\n",
      "Epoch 353/10000\n",
      "20/20 [==============================] - 0s 700us/step - loss: 0.0112\n",
      "Epoch 354/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0111\n",
      "Epoch 355/10000\n",
      "20/20 [==============================] - 0s 925us/step - loss: 0.0111\n",
      "Epoch 356/10000\n",
      "20/20 [==============================] - 0s 600us/step - loss: 0.0111\n",
      "Epoch 357/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0110\n",
      "Epoch 358/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0111\n",
      "Epoch 359/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0111\n",
      "Epoch 360/10000\n",
      "20/20 [==============================] - 0s 950us/step - loss: 0.0111\n",
      "Epoch 361/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0110\n",
      "Epoch 362/10000\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.0110\n",
      "Epoch 363/10000\n",
      "20/20 [==============================] - 0s 375us/step - loss: 0.0110\n",
      "Epoch 364/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0110\n",
      "Epoch 365/10000\n",
      "20/20 [==============================] - 0s 700us/step - loss: 0.0110\n",
      "Epoch 366/10000\n",
      "20/20 [==============================] - 0s 425us/step - loss: 0.0110\n",
      "Epoch 367/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0110\n",
      "Epoch 368/10000\n",
      "20/20 [==============================] - 0s 625us/step - loss: 0.0110\n",
      "Epoch 369/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0110\n",
      "Epoch 370/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0110\n",
      "Epoch 371/10000\n",
      "20/20 [==============================] - 0s 527us/step - loss: 0.0110\n",
      "Epoch 372/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0110\n",
      "Epoch 373/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0110\n",
      "Epoch 374/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0109\n",
      "Epoch 375/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0109\n",
      "Epoch 376/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0109\n",
      "Epoch 377/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 625us/step - loss: 0.0110\n",
      "Epoch 378/10000\n",
      "16/20 [=======================>......] - ETA: 0s - loss: 0.0112"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.842576). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "D:\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.421538). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 525us/step - loss: 0.0109\n",
      "Epoch 379/10000\n",
      "20/20 [==============================] - 0s 975us/step - loss: 0.0109\n",
      "Epoch 380/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0110\n",
      "Epoch 381/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0109\n",
      "Epoch 382/10000\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.0109\n",
      "Epoch 383/10000\n",
      "20/20 [==============================] - 0s 625us/step - loss: 0.0108\n",
      "Epoch 384/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0109\n",
      "Epoch 385/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0109\n",
      "Epoch 386/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0110\n",
      "Epoch 387/10000\n",
      "20/20 [==============================] - 0s 475us/step - loss: 0.0110\n",
      "Epoch 388/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0110\n",
      "Epoch 389/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0110\n",
      "Epoch 390/10000\n",
      "20/20 [==============================] - 0s 650us/step - loss: 0.0110\n",
      "Epoch 391/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0109\n",
      "Epoch 392/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0110\n",
      "Epoch 393/10000\n",
      "20/20 [==============================] - 0s 875us/step - loss: 0.0109\n",
      "Epoch 394/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0109\n",
      "Epoch 395/10000\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.0110\n",
      "Epoch 396/10000\n",
      "20/20 [==============================] - 0s 675us/step - loss: 0.0110\n",
      "Epoch 397/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0110\n",
      "Epoch 398/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0111\n",
      "Epoch 399/10000\n",
      "20/20 [==============================] - 0s 675us/step - loss: 0.0112\n",
      "Epoch 400/10000\n",
      "20/20 [==============================] - 0s 425us/step - loss: 0.0113\n",
      "Epoch 401/10000\n",
      "20/20 [==============================] - 0s 575us/step - loss: 0.0113\n",
      "Epoch 402/10000\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0113\n",
      "Epoch 403/10000\n",
      "20/20 [==============================] - 0s 425us/step - loss: 0.0113\n",
      "Epoch 404/10000\n",
      "20/20 [==============================] - 0s 450us/step - loss: 0.0114\n",
      "Epoch 405/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0115\n",
      "Epoch 406/10000\n",
      "20/20 [==============================] - 0s 425us/step - loss: 0.0117\n",
      "Epoch 407/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0118\n",
      "Epoch 408/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0118\n",
      "Epoch 409/10000\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.0117\n",
      "Epoch 410/10000\n",
      "20/20 [==============================] - 0s 500us/step - loss: 0.0115\n",
      "Epoch 411/10000\n",
      "20/20 [==============================] - 0s 550us/step - loss: 0.0113\n",
      "Epoch 412/10000\n",
      "20/20 [==============================] - 0s 525us/step - loss: 0.0111\n",
      "Epoch 413/10000\n",
      "20/20 [==============================] - 0s 400us/step - loss: 0.0110\n",
      "Epoch 414/10000\n",
      "16/20 [=======================>......] - ETA: 0s - loss: 0.0122"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim = 6, units = 12))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(input_dim = 12, units = 1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.fit(x_train, y_train, epochs = 10000, batch_size = 16)\n",
    "model.save_weights(modelfile)\n",
    "\n",
    "# 预测，并且还原结果\n",
    "x = (\n",
    "    (data_LM[feature_lst] - data_mean[feature_lst]) /\n",
    "     data_std[feature_lst]\n",
    ").as_matrix()\n",
    "data_LM['y_pred'] = model.predict(x) * data_std['y'] + data_mean['y']\n",
    "data_LM['y_pred'] = data_LM['y_pred'].round(2)\n",
    "data_LM.to_excel(outputfile_LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画出预测结果图\n",
    "data_LM[['y', 'y_pred']].plot(subplots = True, style = ['b-o', 'r-*'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-3 增值税预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-3-1 Lasso变量选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile = path + '/data/data2.csv'\n",
    "data2 = pd.read_csv(inputfile)\n",
    "data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lasso(tol = 1)\n",
    "model.fit(data2.iloc[:, 0:6], data2['y'])\n",
    "model.coef_    # 各个特征的系数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-3-2 增值税灰色预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfile_GM11 = path + '/tmp/data2_GM11.xls'    # 灰色预测后保存路径\n",
    "data2.index = range(1999, 2014)\n",
    "\n",
    "data2.loc[2014] = None\n",
    "data2.loc[2015] = None\n",
    "feature_lst = ['x1', 'x3', 'x5']\n",
    "for i in feature_lst:\n",
    "    f = GM11(data2[i][list(range(1999, 2014))].as_matrix())[0]\n",
    "    # 2014年预测结果\n",
    "    data2[i][2014] = f(len(data2) - 1)\n",
    "    # 2015年预测结果\n",
    "    data2[i][2015] = f(len(data2))\n",
    "    # 保留两位小数\n",
    "    data2[i] = data2[i].round(6)\n",
    "\n",
    "print(data2[feature_lst + ['y']])\n",
    "data2[feature_lst + ['y']].to_excel(outputfile_GM11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-3-3 增值税神经网络预测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfile_LM = path + '/data/VAT.xls'\n",
    "modelfile = path + '/tmp/net-VAT.model'\n",
    "\n",
    "data_LM = data2[feature_lst + ['y']]\n",
    "data_train = data_LM.loc[range(1999, 2014)].copy()    # 取2014年前的数据\n",
    "data_mean = data_train.mean()\n",
    "data_std = data_train.std()\n",
    "# 数据标准化\n",
    "data_train = (data_train - data_mean) / data_std\n",
    "    \n",
    "# 特征数据\n",
    "x_train = data_train[feature_lst].as_matrix()\n",
    "# 标签数据\n",
    "y_train = data_train['y'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim = 3, units = 6))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(input_dim = 6, units = 1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.fit(x_train, y_train, epochs = 10000, batch_size = 16)\n",
    "model.save_weights(modelfile)\n",
    "\n",
    "# 预测，并且还原结果\n",
    "x = (\n",
    "    (data_LM[feature_lst] - data_mean[feature_lst]) /\n",
    "     data_std[feature_lst]\n",
    ").as_matrix()\n",
    "data_LM['y_pred'] = model.predict(x) * data_std['y'] + data_mean['y']\n",
    "data_LM['y_pred'] = data_LM['y_pred'].round(6)\n",
    "data_LM.to_excel(outputfile_LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画出预测结果图\n",
    "data_LM[['y', 'y_pred']].plot(subplots = True, style = ['b-o', 'r-*'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-4 营业税预测模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-4-1 Lasso变量选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile = path + '/data/data3.csv'\n",
    "data3 = pd.read_csv(inputfile)\n",
    "data3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lasso(tol = 1)\n",
    "model.fit(data3.iloc[:, 0:10], data3['y'])\n",
    "model.coef_    # 各个特征的系数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-4-2 灰色预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfile_GM11 = path + '/tmp/data3_GM11.xls'    # 灰色预测后保存路径\n",
    "data3.index = range(1999, 2014)\n",
    "\n",
    "data3.loc[2014] = None\n",
    "data3.loc[2015] = None\n",
    "feature_lst = ['x3', 'x4', 'x6', 'x8']\n",
    "for i in feature_lst:\n",
    "    f = GM11(data3[i][list(range(1999, 2014))].as_matrix())[0]\n",
    "    # 2014年预测结果\n",
    "    data3[i][2014] = f(len(data3) - 1)\n",
    "    # 2015年预测结果\n",
    "    data3[i][2015] = f(len(data3))\n",
    "    # 取整\n",
    "    data3[i] = data3[i].round()\n",
    "\n",
    "print(data3[feature_lst + ['y']])\n",
    "data3[feature_lst + ['y']].to_excel(outputfile_GM11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-4-3 神经网络预测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 神经网络预测模型\n",
    "outputfile_LM = path + '/data/sales_tax.xls'\n",
    "modelfile = path + '/tmp/net-sales_tax.model'\n",
    "\n",
    "data_LM = data3[feature_lst + ['y']]\n",
    "data_train = data_LM.loc[range(1999, 2014)].copy()    # 取2014年前的数据\n",
    "data_mean = data_train.mean()\n",
    "data_std = data_train.std()\n",
    "# 数据标准化\n",
    "data_train = (data_train - data_mean) / data_std\n",
    "    \n",
    "# 特征数据\n",
    "x_train = data_train[feature_lst].as_matrix()\n",
    "# 标签数据\n",
    "y_train = data_train['y'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim = 4, units = 8))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(input_dim = 8, units = 1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.fit(x_train, y_train, epochs = 10000, batch_size = 16)\n",
    "model.save_weights(modelfile)\n",
    "\n",
    "# 预测，并且还原结果\n",
    "x = (\n",
    "    (data_LM[feature_lst] - data_mean[feature_lst]) /\n",
    "     data_std[feature_lst]\n",
    ").as_matrix()\n",
    "data_LM['y_pred'] = model.predict(x) * data_std['y'] + data_mean['y']\n",
    "data_LM['y_pred'] = data_LM['y_pred'].round(2)\n",
    "data_LM.to_excel(outputfile_LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画出预测结果图\n",
    "data_LM[['y', 'y_pred']].plot(subplots = True, style = ['b-o', 'r-*'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-5 企业所得税预测模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-5-1 Lasso变量选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile = path + '/data/data4.csv'\n",
    "data4 = pd.read_csv(inputfile)\n",
    "data4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lasso(tol = 1)\n",
    "model.fit(data4.iloc[:, 0:10], data4['y'])\n",
    "model.coef_    # 各个特征的系数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-5-2 灰色预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfile_GM11 = path + '/tmp/data4_GM11.xls'    # 灰色预测后保存路径\n",
    "data4.index = range(2002, 2014)\n",
    "\n",
    "data4.loc[2014] = None\n",
    "data4.loc[2015] = None\n",
    "feature_lst = ['x1', 'x2', 'x3', 'x4', 'x6', 'x7', 'x9', 'x10']\n",
    "for i in feature_lst:\n",
    "    f = GM11(data4[i][list(range(2002, 2014))].as_matrix())[0]\n",
    "    # 2014年预测结果\n",
    "    data4[i][2014] = f(len(data4) - 1)\n",
    "    # 2015年预测结果\n",
    "    data4[i][2015] = f(len(data4))\n",
    "    data4[i] = data4[i].round(2)\n",
    "\n",
    "print(data4[feature_lst + ['y']])\n",
    "data4[feature_lst + ['y']].to_excel(outputfile_GM11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-5-3 神经网络预测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfile_LM = path + '/data/enterprise_income.xls'\n",
    "modelfile = path + '/tmp/net-enterprise_income.model'\n",
    "\n",
    "data_LM = data4[feature_lst + ['y']]\n",
    "data_train = data_LM.loc[range(2002, 2014)].copy()    # 取2014年前的数据\n",
    "data_mean = data_train.mean()\n",
    "data_std = data_train.std()\n",
    "# 数据标准化\n",
    "data_train = (data_train - data_mean) / data_std\n",
    "    \n",
    "# 特征数据\n",
    "x_train = data_train[feature_lst].as_matrix()\n",
    "# 标签数据\n",
    "y_train = data_train['y'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim = 8, units = 6))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(input_dim = 6, units = 1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.fit(x_train, y_train, epochs = 10000, batch_size = 16)\n",
    "model.save_weights(modelfile)\n",
    "\n",
    "# 预测，并且还原结果\n",
    "x = (\n",
    "    (data_LM[feature_lst] - data_mean[feature_lst]) /\n",
    "     data_std[feature_lst]\n",
    ").as_matrix()\n",
    "data_LM['y_pred'] = model.predict(x) * data_std['y'] + data_mean['y']\n",
    "data_LM['y_pred'] = data_LM['y_pred'].round()\n",
    "data_LM.to_excel(outputfile_LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画出预测结果图\n",
    "data_LM[['y', 'y_pred']].plot(subplots = True, style = ['b-o', 'r-*'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-6 个人所得税预测模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-6-1 Lasso变量选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile = path + '/data/data5.csv'\n",
    "data5 = pd.read_csv(inputfile)\n",
    "data5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lasso(tol = 1)\n",
    "model.fit(data5.iloc[:, 0:7], data5['y'])\n",
    "model.coef_    # 各个特征的系数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-6-2 灰色预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfile_GM11 = path + '/tmp/data5_GM11.xls'    # 灰色预测后保存路径\n",
    "data5.index = range(2000, 2014)\n",
    "\n",
    "data5.loc[2014] = None\n",
    "data5.loc[2015] = None\n",
    "feature_lst = ['x1', 'x4', 'x5', 'x7']\n",
    "for i in feature_lst:\n",
    "    f = GM11(data5[i][list(range(2000, 2014))].as_matrix())[0]\n",
    "    # 2014年预测结果\n",
    "    data5[i][2014] = f(len(data5) - 1)\n",
    "    # 2015年预测结果\n",
    "    data5[i][2015] = f(len(data5))\n",
    "    data5[i] = data5[i].round()\n",
    "\n",
    "print(data5[feature_lst + ['y']])\n",
    "data5[feature_lst + ['y']].to_excel(outputfile_GM11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-6-3 神经网络预测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfile_LM = path + '/data/personal_income.xls'\n",
    "modelfile = path + '/tmp/net-personal_income.model'\n",
    "\n",
    "data_LM = data5[feature_lst + ['y']]\n",
    "data_train = data_LM.loc[range(2000, 2014)].copy()    # 取2014年前的数据\n",
    "data_mean = data_train.mean()\n",
    "data_std = data_train.std()\n",
    "# 数据标准化\n",
    "data_train = (data_train - data_mean) / data_std\n",
    "    \n",
    "# 特征数据\n",
    "x_train = data_train[feature_lst].as_matrix()\n",
    "# 标签数据\n",
    "y_train = data_train['y'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim = 4, units = 8))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(input_dim = 8, units = 1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.fit(x_train, y_train, epochs = 15000, batch_size = 16)\n",
    "model.save_weights(modelfile)\n",
    "\n",
    "# 预测，并且还原结果\n",
    "x = (\n",
    "    (data_LM[feature_lst] - data_mean[feature_lst]) /\n",
    "     data_std[feature_lst]\n",
    ").as_matrix()\n",
    "data_LM['y_pred'] = model.predict(x) * data_std['y'] + data_mean['y']\n",
    "data_LM['y_pred'] = data_LM['y_pred'].round()\n",
    "data_LM.to_excel(outputfile_LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画出预测结果图\n",
    "data_LM[['y', 'y_pred']].plot(subplots = True, style = ['b-o', 'r-*'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13-7 政府性基金收入灰色预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([3152063, 2213050, 4050122,\n",
    "               5265142, 5556619, 4772843, 9463330])\n",
    "f, a, b, x00, C, P = GM11(x0)\n",
    "print(a, b, x00, C, P)\n",
    "print('\\n')\n",
    "print(u'2014年、2015年的预测结果分别为：\\n%0.2f万元和%0.2f万元' % (f(8), f(9)))\n",
    "print(u'后验差比值为：%0.4f' % C)\n",
    "data = pd.DataFrame(x0, columns = ['y'], index = range(2007, 2014))\n",
    "data.loc[2014] = None\n",
    "data.loc[2015] = None\n",
    "data['y_pred'] = [f(i) for i in range(1, 10)]\n",
    "data['y_pred'] = data['y_pred'].round(2)\n",
    "data.index = pd.to_datetime(data.index, format = '%Y')\n",
    "\n",
    "data.plot(style = ['b-o', 'r-*'], xticks = data.index)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
